import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import (
    accuracy_score,
    f1_score,
    confusion_matrix,
    roc_curve,
    auc
)

# ----------------------------------------------------------------------
# Загрузка и предобработка исходного датасета
# ----------------------------------------------------------------------
def load_and_preprocess_db3(path: str) -> pd.DataFrame:
    """
    Загружает таблицу из файла path и выполняет базовую предобработку.

    Основные шаги:
      1. Загрузка данных (разделитель — табуляция).
      2. Очистка имён столбцов от служебных символов.
      3. Удаление пустых и служебных столбцов.
      4. One-hot кодирование категориальных признаков.
      5. Удаление строк с пропусками.

    Возвращает:
        pd.DataFrame: обработанный датафрейм.
    """
    # Загрузка CSV с разделителем табуляция
    df = pd.read_csv(path, sep="\t")

    # Очистка названий колонок от символов табуляции, кавычек и пробелов
    df.columns = (
        df.columns
        .str.replace(r'[\t"]', '', regex=True)
        .str.strip()
    )

    # Удаление полностью пустых столбцов
    df = df.dropna(axis=1, how="all")

    # Удаление идентификатора пользователя, если он присутствует
    if "user_id" in df.columns:
        df = df.drop(columns=["user_id"])

    # Проверка наличия целевого столбца
    target_col = "mental_wellness_index_0_100"
    if target_col not in df.columns:
        raise ValueError(f"Столбец '{target_col}' отсутствует в данных")

    # Определение категориальных признаков
    categorical_cols = df.select_dtypes(include=["object"]).columns.tolist()
    categorical_cols = [c for c in categorical_cols if c != target_col]

    # One-hot кодирование категориальных признаков
    df_processed = pd.get_dummies(
        df,
        columns=categorical_cols,
        drop_first=True
    )

    # Удаление строк с пропусками
    df_processed = df_processed.dropna().reset_index(drop=True)

    return df_processed


# ----------------------------------------------------------------------
# Обучение модели и визуализация результатов
# ----------------------------------------------------------------------
def classification_training(data: pd.DataFrame) -> None:
    """
    Обучает модель случайного леса для бинарной классификации
    показателя mental_wellness_index_0_100 и визуализирует результаты.

    Шаги:
      1. Бинаризация целевой переменной: <15 → 0, >=15 → 1.
      2. Разделение на обучающую и тестовую выборки.
      3. Подбор гиперпараметров RandomForest через GridSearchCV (F1-score).
      4. Обучение финальной модели с найденными параметрами.
      5. Расчёт accuracy и F1-score на тестовой выборке.
      6. Визуализация:
           • матрица ошибок;
           • ROC-кривая и площадь под кривой (AUC);
           • важность признаков (top-10).
    """
    target_col = "mental_wellness_index_0_100"
    if target_col not in data.columns:
        raise ValueError(f"В датафрейме отсутствует столбец '{target_col}'")

    # Копия датафрейма, чтобы не изменять исходные данные
    df = data.copy()

    # Бинаризация таргета по порогу 15
    df[target_col] = np.where(df[target_col] < 15, 0, 1)

    # Матрица признаков и целевая переменная
    y = df[target_col]
    X = df.drop(columns=[target_col])

    # Удаление строк с пропусками
    X = X.dropna()
    y = y.loc[X.index]

    # Разделение на обучающую и тестовую выборки
    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=0.2,
        random_state=42,
        stratify=y
    )

    # Базовый классификатор случайного леса
    base_rf = RandomForestClassifier(
        random_state=42,
        n_jobs=-1
    )

    # Сетка гиперпараметров для поиска
    param_grid = {
        "n_estimators": [100],
        "max_depth": [None, 10],
        "min_samples_split": [2],
        "min_samples_leaf": [1],
        "max_features": ["sqrt"],
    }

    # GridSearchCV по метрике F1
    grid_search = GridSearchCV(
        estimator=base_rf,
        param_grid=param_grid,
        scoring="f1",
        cv=5,
        n_jobs=-1,
        verbose=0
    )

    # Обучение GridSearchCV
    grid_search.fit(X_train, y_train)

    # Вывод лучших гиперпараметров
    best_params = grid_search.best_params_
    print("Лучший набор гиперпараметров RandomForest:")
    print(best_params)

    # Итоговая модель с найденными гиперпараметрами
    best_rf = RandomForestClassifier(
        random_state=42,
        n_jobs=-1,
        **best_params
    )
    best_rf.fit(X_train, y_train)

    # Предсказания и вероятности на тестовой выборке
    y_pred = best_rf.predict(X_test)
    y_proba = best_rf.predict_proba(X_test)[:, 1]

    # Расчёт метрик качества
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    print(f"RF: {acc:.4f}; {f1:.4f}")

    # ------------------------------------------------------------------
    # Визуализации
    # ------------------------------------------------------------------

    # 1. Матрица ошибок
    cm = confusion_matrix(y_test, y_pred)

    plt.figure(figsize=(4, 4))
    plt.imshow(cm, interpolation="nearest")
    plt.title("Confusion matrix (RandomForest)")
    plt.colorbar()
    tick_marks = np.arange(2)
    plt.xticks(tick_marks, ["0", "1"])
    plt.yticks(tick_marks, ["0", "1"])
    plt.xlabel("Predicted label")
    plt.ylabel("True label")

    # Подписи значений внутри ячеек
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, cm[i, j],
                     ha="center", va="center")
    plt.tight_layout()
    # при необходимости можно сохранить рисунок:
    # plt.savefig("confusion_matrix_rf.png", dpi=300)
    plt.show()

    # 2. ROC-кривая и AUC
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    roc_auc = auc(fpr, tpr)

    plt.figure(figsize=(5, 5))
    plt.plot(fpr, tpr, label=f"RF (AUC = {roc_auc:.3f})")
    plt.plot([0, 1], [0, 1], linestyle="--")  # линия случайного классификатора
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC-curve (RandomForest)")
    plt.legend(loc="lower right")
    plt.tight_layout()
    # plt.savefig("roc_rf.png", dpi=300)
    plt.show()

    # 3. Важность признаков (топ-10)
    importances = best_rf.feature_importances_
    indices = np.argsort(importances)[::-1]

    top_n = min(10, len(indices))
    top_idx = indices[:top_n]
    top_features = X.columns[top_idx]
    top_values = importances[top_idx]

    plt.figure(figsize=(8, 4))
    plt.bar(range(top_n), top_values, align="center")
    plt.xticks(range(top_n), top_features, rotation=45, ha="right")
    plt.ylabel("Feature importance")
    plt.title("Top important features (RandomForest)")
    plt.tight_layout()
    # plt.savefig("feature_importance_rf.png", dpi=300)
    plt.show()


# ----------------------------------------------------------------------
# Основной блок запуска скрипта
# ----------------------------------------------------------------------
if __name__ == "__main__":
    # Вывод текущей рабочей директории (для контроля пути к файлу)
    print("Текущая рабочая директория:", os.getcwd())

    # Вариант подключения файла:
    # файл находится в папке Загрузки (Downloads) пользователя
    path_option_1 = r"C:\Users\Andrey\Downloads\DB_3 (1).csv"

    # При необходимости можно использовать другие варианты:
    # (файл рядом со скриптом)
    # path_option_1 = r"DB_3 (1).csv"
    #
    # (файл в подпапке проекта, например project/data/)
    # path_option_1 = r"data\DB_3 (1).csv"

    # Проверка существования файла по выбранному пути
    if os.path.exists(path_option_1):
        print("Файл найден по пути:", path_option_1)
        final_path = path_option_1
    else:
        raise FileNotFoundError(
            f"Файл 'DB_3 (1).csv' не найден. "
            f"Проверьте корректность пути:\n{path_option_1}"
        )

    # Загрузка и предобработка данных
    data_for_training = load_and_preprocess_db3(final_path)

    # Обучение модели и визуализация результатов
    classification_training(data_for_training)
